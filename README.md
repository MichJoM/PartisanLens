# ğŸ•µï¸â€â™‚ï¸ PartisanLens: A Multilingual Dataset of Hyperpartisan and Conspiratorial Immigration Narratives in European Media

**PartisanLens** is a dataset focused on hyperpartisanship, stance detection, and PRCT, featuring human-authored rationales and detailed annotations.

---

## ğŸ“ Repository Structure

```
partisanlens/
â”‚
â”œâ”€â”€ data/ ğŸ“¦ Dataset, keywords & rationales
â”œâ”€â”€ data_curation/ ğŸ§ª Data sampling, statistics, and analysis scripts
â”‚ â”œâ”€â”€ analysis/ ğŸ“Š Data analysis scripts
â”‚ â””â”€â”€ DPP_extraction.py
â”œâ”€â”€ experiments/ ğŸ§  Model training, inference, rationale generation
â”‚ â”œâ”€â”€ build-templated-rationales.py
â”‚ â”œâ”€â”€ rephrase-rationales.py
â”‚ â”œâ”€â”€ inference.py
â”‚ â””â”€â”€ finetune.py
â””â”€â”€ annotation_guidelines.pdf ğŸ“„ Annotation schema and instructions
```

---

## ğŸ“Œ Dataset Overview

**PartisanLens** includes:

- ğŸ”´ğŸ”µ **Hyperpartisan annotations** â€“ identifying overtly partisan language  
- ğŸ§­ **Stance detection** â€“ determining whether the speaker is *pro*, *against*, or *neutral* towards immigration  
- ğŸ§  **PRCT labels** â€“ Population Replacement Conspiracy Theories  

Each sample contains:
- A political *text segment*
- Task-specific labels (hyperpartisan, stance, PRCT)
- Span annotation (loaded language, name calling and appeal to fear)

---

## ğŸ”¬ Experiments

We provide Python scripts to explore how LLMs and finetuned models handle reasoning with rationales.

| Module | Description                                                                                  |
|--------|----------------------------------------------------------------------------------------------|
| ğŸ§± `build-templated-rationales.py` | Automatically build templated rationales from the span annotation                            |
| âœï¸ `rephrase-rationales.py` | Rephrase or augment rationales using LLMs for more fluente and natural language explanations |
| ğŸ¤– `inference.py` | Perform zero-shot or few-shot inference using LLMs                                           |
| ğŸ¯ `finetune.py` | Finetune models with (or without) rationale supervision                                      |

### âœï¸ Rephrasing Rationales â€” `rephrase-rationales.py`

This script uses a LLM to **rephrase and enrich templated rationales** for each instance in the dataset, while preserving the original task labels. The output is a step-by-step explanation in JSON format for each example.

#### ğŸ”§ How to Run

```bash
python3 experiments/rephrase-rationales.py \
  --dataset data/train_templated_rationales.csv \
  --output data/train_rephrased_rationales.csv \
  --hf_token your_huggingface_token
```
#### ğŸ”§ Arguments

| Argument                        | Type   | Required | Description                                                                                                                                                                           |
|---------------------------------|--------|----------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `--dataset`                     | `str`  | âœ… Yes    | Path to the input dataset (`.csv` or `.tsv`). Must include columns like `id`, `text`, `templated_rationales`, `hyperpartisan_gold_label`, `prct_gold_label`, and `stance_gold_label`. |
| `--output`                      | `str`  | âŒ No     | Path to the output file (`.csv`). Default: `rephrased-rationales.csv`.                                                                                                                |
| `--hf_token`                    | `str`  | âŒ No     | Hugging Face token (used to access gated models from the `unsloth` hub).                                                                                                              |


### ğŸ¤– Inference â€” `inference.py`

This script performs **LLM-based inference** using zero-shot or few-shot prompting, either to generate **rationales** and **predict labels** or only **predict labels**. You can select different models and modes depending on your use case.

#### â–¶ï¸ How to Run

```bash
python3 experiments/inference.py \
  --dataset data/test.csv \
  --model llama3.3-70 \
  --mode rationales \
  --output data/predictions.tsv \
  --hf_token your_huggingface_token
```

#### ğŸ§© Modes of Operation

You can choose between two modes when running the script:

| Mode        | Description                                                                 |
|-------------|-----------------------------------------------------------------------------|
| `rationales`| ğŸ” Generates natural language rationales (chain-of-thought explanations) for each input sentence. |
| `labels`    | ğŸ·ï¸ Directly predicts the classification labels: `hyperpartisan`, `PRCT`, and `stance` â€” without generating a rationale. |

#### ğŸ”§ Arguments

| Argument       | Type   | Required | Description                                                                 |
|----------------|--------|----------|-----------------------------------------------------------------------------|
| `--dataset`    | `str`  | âœ… Yes    | Path to the input dataset (`.csv` or `.tsv`). Must include a `text` column. |
| `--model`      | `str`  | âœ… Yes    | Model identifier. Must be one of: `llama3.1-8b`, `llama3.3-70`, `nemo`.     |
| `--output`     | `str`  | âŒ No     | Path to the output predictions file. Default: `rephrased-rationales.csv`.   |
| `--mode`       | `str`  | âŒ No     | Whether to generate `"rationales"` or `"labels"`. Default: `rationales`.    |
| `--hf_token`   | `str`  | âŒ No     | Hugging Face token for accessing gated models (e.g., LLaMA-3).              |

### ğŸš€ Fine-tuning â€” `finetune.py`

Fine-tune a model on the dataset with options for generating either rationales or labels.

```bash
python3 finetune.py \
  --dataset data/train.csv \
  --model MODEL_NAME llama3.3-70
```
#### ğŸ”§ Arguments

| Argument           | Type   | Required | Description                                                                                                      |
|--------------------|--------|----------|------------------------------------------------------------------------------------------------------------------|
| `--dataset`        | `str`  | âœ… Yes    | Path to the input dataset (`.csv` or `.tsv`) containing the training data. Must include `text`and label columns. |
| `--model`          | `str`  | âœ… Yes    | Model to fine-tune. Must be one of: `llama3.1-8b`, `llama3.3-70`, `nemo`.                                        |
| `--new_model_name` | `str`  | âŒ No     | File name/path for saving the fine-tuned model and tokenizer. Default: `new-model`.                              |
| `--mode`           | `str`  | âŒ No     | Mode of fine-tuning: `"rationales"` for explanations or `"labels"` for only classification labels.               |
| `--hf_token`       | `str`  | âŒ No     | Hugging Face token for accessing gated models (e.g., LLaMA-3).                                                   |


---

## ğŸ“Š Data Curation

The `data_curation/` directory contains:

- ğŸ“ˆ Scripts for analyzing dataset composition  
- âš–ï¸ Sampling strategies used the create the dataset  
- ğŸ§® Statistical reports and visualizations  

---

## ğŸ“š Annotation Guidelines

Full documentation of tasks, labeling protocols, and rationale-writing instructions are provided in:

ğŸ“„ `annotation_guidelines.pdf`


---

## ğŸ’¡ Use Cases

- ğŸ§  **Interpretability research using rationales**  
  Use the human-curated / LLM-improved rationales to evaluate and improve model transparency and explainability.

- ğŸ” **Political bias and stance analysis**  
  Study how models detect hyperpartisan language and take stances toward immigration claims.

- ğŸ¤– **Fine-tuning models with explanation supervision**  
  Train models not only to classify but also to generate or use rationales, improving generalization and trustworthiness.

---

## ğŸ“ Citation

ğŸ“Œ *Coming soon â€“ paper under submission.*  
If you use this resource, please â­ star the repo and stay tuned for citation info.

---


## ğŸ™ Acknowledgements 

The authors thank the funding from the Horizon Europe research and innovation programme under the Marie SkÅ‚odowska-Curie Grant Agreement No. 101073351. The authors also thank the financial support supplied by the ConsellerÃ­a de Cultura, EducaciÃ³n, FormaciÃ³n Profesional e Universidades (accreditation 2019-2022 ED431G/01, ED431B 2022/33) and the European Regional Development Fund, which acknowledges the CITIC Research Center in ICT of the University of A CoruÃ±a as a Research Center of the Galician University System and the project PID2022-137061OB-C21 (Ministerio de Ciencia e InnovaciÃ³n, Agencia Estatal de InvestigaciÃ³n, Proyectos de GeneraciÃ³n de Conocimiento; supported by the European Regional Development Fund). The authors also thank the funding of project PLEC2021-007662 (MCIN/AEI/10.13039/501100011033, Ministerio de Ciencia e InnovaciÃ³n, Agencia Estatal de InvestigaciÃ³n, Plan de RecuperaciÃ³n, TransformaciÃ³n y Resiliencia, UniÃ³n Europea-Next Generation EU).

---

## ğŸ“¬ Contact

For questions, please reach out via email: `michelejoshua.maggini@usc.es` or `paloma.piot@udc.es`




